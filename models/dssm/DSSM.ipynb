{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import implicit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import  tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4349/4349 [00:13<00:00, 328.05it/s]\n"
     ]
    }
   ],
   "source": [
    "IS_LOCAL = False\n",
    "HOME_DIR = ('/mnt/E/Projects/' if IS_LOCAL else '/home/Xetd71/') + 'Content-based-Neural-Recommender-Systems/'\n",
    "os.environ['HOME_DIR'] = HOME_DIR\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from utils.prepare_data import zen, tokenize\n",
    "from utils.evaluate import test\n",
    "from utils import tqdm_utils\n",
    "\n",
    "DATA_DIR = f'{HOME_DIR}data/zen/'\n",
    "WORKING_DIR = f'{HOME_DIR}models/dssm'\n",
    "os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS = 42977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading items: 328050it [00:35, 9239.84it/s] \n"
     ]
    }
   ],
   "source": [
    "items_df = zen.items_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_DIR = f'{DATA_DIR}preproc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42977, 64) (42977, 1)\n",
      "(67780168, 3) (61329513, 3) (6450655, 3)\n"
     ]
    }
   ],
   "source": [
    "# users\n",
    "users_factors = np.load(f'{PREPROC_DIR}users_factors.npy')\n",
    "users_mean_ratings = np.load(f'{PREPROC_DIR}users_mean_ratings.npy')\n",
    "print(users_factors.shape, users_mean_ratings.shape)\n",
    "\n",
    "# ratings\n",
    "ratings_matrix = np.load(f'{PREPROC_DIR}ratings_matrix.npy')\n",
    "ratings_0_matrix = np.load(f'{PREPROC_DIR}ratings_0_matrix.npy')\n",
    "ratings_1_matrix = np.load(f'{PREPROC_DIR}ratings_1_matrix.npy')\n",
    "print(ratings_matrix.shape, ratings_0_matrix.shape, ratings_1_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9048297578725387, 0.09517024212746124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = ratings_1_matrix.shape[0]/ratings_matrix.shape[0]\n",
    "w0 = ratings_0_matrix.shape[0]/ratings_matrix.shape[0]\n",
    "w0, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_texts = (items_df['title'] + ' ' + items_df['content']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 954 ms, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remove_f = 0.000001\n",
    "VOCAB_SIZE = 1_000_000\n",
    "bag_of_words = CountVectorizer(tokenizer=tokenize, min_df=remove_f, max_df=1-remove_f, max_features=VOCAB_SIZE)\n",
    "items_matrix = bag_of_words.fit_transform(items_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<328050x1000000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 53898613 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6450655/6450655 [00:10<00:00, 627753.73it/s]\n"
     ]
    }
   ],
   "source": [
    "user_items_ids = {}\n",
    "for user, item, _ in tqdm(ratings_1_matrix):\n",
    "    if user in user_items_ids:\n",
    "        user_items_ids[user].append(item)\n",
    "    else:\n",
    "        user_items_ids[user] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42977/42977 [09:33<00:00, 74.95it/s]\n"
     ]
    }
   ],
   "source": [
    "users_matrix = []\n",
    "for user in tqdm(np.arange(N_USERS)):\n",
    "    users_matrix.append(sparse.csr_matrix(items_matrix[user_items_ids[user]].mean(axis=0)))\n",
    "users_matrix = sparse.vstack(users_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42977, 1000000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000000-1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625489"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "625489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings_batch(ratings_matrix=ratings_matrix, batch_size=64):\n",
    "    idxs = np.random.randint(0, ratings_matrix.shape[0], batch_size)\n",
    "    items = ratings_matrix[idxs]\n",
    "    return users_matrix[items[:, 0]].toarray(), items_matrix[items[:, 1]].toarray(), items[:, 2].T\n",
    "\n",
    "def normalized_ratings_batch(batch_size=64):\n",
    "    sparse.vstack\n",
    "    return tuple(map(lambda x: np.concatenate((x[0], x[1])), zip(\n",
    "        ratings_batch(ratings_0_matrix, batch_size // 2), \n",
    "        ratings_batch(ratings_1_matrix, batch_size - batch_size // 2)\n",
    "    )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:12:13.491949Z",
     "start_time": "2018-11-07T16:12:13.485091Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m8sJ5diMN4Ze"
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, dot, Reshape, Dropout, Activation, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:15:15.162847Z",
     "start_time": "2018-11-07T16:15:15.148961Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qB6fLEF8N4Zg"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    user_embedding = Input(dtype='float32', shape=(VOCAB_SIZE,), name='user_embedding') \n",
    "    item_embedding = Input(dtype='float32', shape=(VOCAB_SIZE,), name='item_embedding')\n",
    "    \n",
    "    user_layer = Dense(300, activation=\"elu\", input_shape=(VOCAB_SIZE,))(user_embedding)\n",
    "    user_layer = Dense(300, activation=\"elu\", input_shape=(300,))(user_layer)\n",
    "    user_layer = Dropout(0.3)(user_layer)\n",
    "    user_layer = Dense(128, activation=None, input_shape=(300,))(user_layer)\n",
    "    \n",
    "    item_layer = Dense(300, activation=\"elu\", input_shape=(VOCAB_SIZE,))(item_embedding)\n",
    "    item_layer = Dense(300, activation=\"elu\", input_shape=(300,))(item_layer)\n",
    "    item_layer = Dropout(0.3)(item_layer)\n",
    "    item_layer = Dense(128, activation=None, input_shape=(300,))(item_layer)\n",
    "    \n",
    "    user_item_product = dot([user_layer, item_layer], axes=1)\n",
    "    pred_y = Activation(\"sigmoid\")(user_item_product)\n",
    "    \n",
    "    model = Model(inputs=[user_embedding, item_embedding], outputs=pred_y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:15:16.796282Z",
     "start_time": "2018-11-07T16:15:16.726472Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "nbXZEqU8N4Zj",
    "outputId": "d36d47f0-e91f-4478-8a68-f29cfb42a7c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_embedding (InputLayer)     (None, 1000000)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (InputLayer)     (None, 1000000)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          300000300   user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          300000300   item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          90300       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          90300       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          38528       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          38528       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 600,258,256\n",
      "Trainable params: 600,258,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:16:27.284265Z",
     "start_time": "2018-11-07T16:16:27.184294Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pS5TKAcxN4Zo"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 10_000\n",
    "EPOCHS = 100\n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.adam(),  # gradient clipping just in case\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:20:03.725667Z",
     "start_time": "2018-11-07T16:20:03.715510Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "yYeewJvKN4Zq"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name, period):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "        self.period = period\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        if (epoch + 1) % self.period == 0:\n",
    "            save_model(self.model, model_filename)\n",
    "            print(f\"Model saved in {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dssm_predict(user_id, items):\n",
    "    return model.predict([users_matrix[[user_id]*len(items)],  items_matrix[items]])[:, 0]\n",
    "\n",
    "def prediction_hist(p, bins=5):\n",
    "    hist = []\n",
    "    for th in np.linspace(0, 1-1/bins, bins):\n",
    "        hist.append(np.logical_and(th <= p, p <= (th+1/bins)).sum())\n",
    "    return hist\n",
    "\n",
    "def dssm_get_prediction_hist(bins=5):\n",
    "    user_embedding, item_embeddings, ratings = normalized_ratings_batch(batch_size=BATCH_SIZE)\n",
    "    return prediction_hist(model.predict([user_embedding, item_embeddings])[:, 0], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelLogFileCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelLogFileCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "        \n",
    "    def on_train_begin(self, logs):\n",
    "        self.file = open(self.file_name, 'a+')\n",
    "        self.epoch_time = time.time()\n",
    " \n",
    "    def on_train_end(self, logs):\n",
    "        self.file.close()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ndcg = test.ndcg(dssm_predict)\n",
    "        p_hist = dssm_get_prediction_hist()\n",
    "        cur_time = time.time()\n",
    "        logs['ndcg'] = ndcg\n",
    "        msg = \"Epoch {},   loss: {:.4f},   val ndcg: {:.4f},   p_hist: [{}],   time: {:.4f}\".format(\n",
    "            epoch,\n",
    "            logs.get('loss'),\n",
    "            ndcg,\n",
    "            ', '.join(list(map(str, p_hist))),\n",
    "            cur_time - self.epoch_time,\n",
    "        )\n",
    "        print(msg)\n",
    "        print(msg, file=self.file, flush=True)\n",
    "        self.epoch_time = cur_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:22:04.352396Z",
     "start_time": "2018-11-07T16:22:03.726954Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sh2rYSX8N4Zs"
   },
   "outputs": [],
   "source": [
    "last_finished_epoch = 0\n",
    "\n",
    "# you can continue from snapshot!!!\n",
    "# from keras.models import load_model\n",
    "# s = reset_tf_session()\n",
    "# last_finished_epoch = 103\n",
    "# model = load_model(path(\"model4/model_{}\".format(last_finished_epoch)), \n",
    "#                    custom_objects={\"top_3_accuracy\": top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    while True:\n",
    "        user_id, item_embeddings, ratings = normalized_ratings_batch(batch_size=batch_size)\n",
    "#         user_id, item_embeddings, ratings = ratings_batch(batch_size=batch_size, ratings_matrix=ratings_matrix)\n",
    "        yield [user_id, item_embeddings], ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tensorboard = TensorBoard(log_dir=f\"/data/home/Xetd71/DSSM/logs/{time.time()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T16:22:12.823711Z",
     "start_time": "2018-11-07T16:22:08.154274Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1164
    },
    "colab_type": "code",
    "id": "FB-E1UrXN4Zv",
    "outputId": "5b3ad4bd-6fe3-48d7-c78b-66cc7f675887",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1000000,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/mul_11 (defined at /anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:466)  = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable_2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/mul_11', defined at:\n  File \"/anaconda/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-14f5739a2d8e>\", line 12, in <module>\n    initial_epoch=last_finished_epoch,\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 2080, in fit_generator\n    self._make_train_function()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py\", line 466, in get_updates\n    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 856, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 878, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5042, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1000000,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/mul_11 (defined at /anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:466)  = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable_2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1000000,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/mul_11}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable_2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-14f5739a2d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_finished_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#     class_weight={0: w0, 1: w1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1000000,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/mul_11 (defined at /anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:466)  = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable_2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/Adam/mul_11', defined at:\n  File \"/anaconda/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/anaconda/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-14f5739a2d8e>\", line 12, in <module>\n    initial_epoch=last_finished_epoch,\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 2080, in fit_generator\n    self._make_train_function()\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py\", line 466, in get_updates\n    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 856, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 878, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5042, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1000000,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node training/Adam/mul_11 (defined at /anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:466)  = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/beta_1/read, training/Adam/Variable_2/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# fit the model with our eternal generator!\n",
    "model.fit_generator(\n",
    "    train_iterator(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        ModelSaveCallback(\"/data/home/Xetd71/DSSM/model_{}\", 1),\n",
    "        ModelLogFileCallback(\"/data/home/Xetd71/DSSM/logs.txt\"),\n",
    "        tensorboard,\n",
    "    ],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch,\n",
    "#     class_weight={0: w0, 1: w1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
