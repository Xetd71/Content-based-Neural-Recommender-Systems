{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import gzip\n",
    "import json\n",
    "import implicit\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL = False\n",
    "HOME_DIR = '/mnt/E/Projects/Content-based-Neural-Recommender-Systems/' if IS_LOCAL else '../../'\n",
    "os.environ['HOME_DIR'] = HOME_DIR\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from utils.prepare_data import utf8_preview\n",
    "\n",
    "DATA_DIR = f'{HOME_DIR}data/zen/'\n",
    "WORKING_DIR = f'{HOME_DIR}/models/als_item_vector_prediction/'\n",
    "os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eb083267304f2696524c6301d16cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='loading items', max=1, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_size = 96\n",
    "items_df = []\n",
    "for line in tqdm(gzip.GzipFile(f\"{DATA_DIR}items.json.gz\", \"r\"), 'loading items'):\n",
    "    j = json.loads(line)\n",
    "    j[\"content\"] = j[\"content\"].encode(\"utf8\")  # storing in utf8 saves RAM\n",
    "    j[\"title\"] = j[\"title\"].encode(\"utf8\")\n",
    "    if np.isnan(j[\"image\"]).any():\n",
    "        j[\"image\"] = [0]*image_size\n",
    "    items_df.append(j)\n",
    "items_df = pd.DataFrame(items_df).apply(utf8_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_n = int(items_df.shape[0]*(1-test_size))\n",
    "items_train_df, items_test_df = items_df.iloc[:split_n], items_df.iloc[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262440, 4), (65610, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train_df.shape, items_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_items(user_items, user_ratings, split_n):\n",
    "    user_items, user_ratings = np.array(user_items), np.array(user_ratings)\n",
    "    train_idxs = user_items < split_n\n",
    "    test_idxs = train_idxs ^ True\n",
    "    return (user_items[train_idxs], user_ratings[train_idxs]), (user_items[test_idxs], user_ratings[test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e665a5949041491299ab1ea78c66c1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='loading users', max=1, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "users_train_df, users_test_df = [], []\n",
    "for line in tqdm(gzip.GzipFile(f\"{DATA_DIR}train.json.gz\", \"r\"), 'loading users'):\n",
    "    j = json.loads(line)\n",
    "    user_items = []\n",
    "    user_ratings = []\n",
    "    for item, rating in j[\"trainRatings\"].items():\n",
    "        user_items.append(int(item))\n",
    "        user_ratings.append(int(rating))\n",
    "\n",
    "    user_train, user_test = split_items(user_items, user_ratings, split_n)\n",
    "    users_train_df.append({\n",
    "        'userId': j[\"userId\"],\n",
    "        'userItems': np.array(user_train[0]),\n",
    "        'userRatings': np.array(user_train[1]),\n",
    "    })\n",
    "    users_test_df.append({\n",
    "        'userId': j[\"userId\"],\n",
    "        'userItems': np.array(user_test[0]),\n",
    "        'userRatings': np.array(user_test[1]),\n",
    "    })\n",
    "users_train_df = pd.DataFrame(users_train_df)\n",
    "users_test_df = pd.DataFrame(users_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = users_train_df, users_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for t in train_df['userItems']:\n",
    "    tmp += t.tolist()\n",
    "for t in test_df['userItems']:\n",
    "    tmp += t.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328049"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262436"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_df['userItems'].apply(max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSR-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.concatenate([[v]*v_len for v, v_len in zip(\n",
    "    train_df['userId'].values, train_df['userItems'].apply(len).values)])\n",
    "items_ids = np.concatenate(train_df['userItems'].values)\n",
    "ratings = np.concatenate(np.array(list(map(lambda x: x - x.mean(), train_df['userRatings'].values))))\n",
    "item_user_data = sparse.csr_matrix((ratings, (items_ids, user_ids)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = np.array(list(map(np.mean, train_df['userRatings'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262437, 42977)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_n: 42977\titems_n: 262436\n"
     ]
    }
   ],
   "source": [
    "users_n = train_df.shape[0]\n",
    "items_n = train_df['userItems'].apply(max).max()\n",
    "print(f'users_n: {users_n}\\titems_n: {items_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 20.0/20 [02:20<00:00,  7.00s/it, loss=-.0051] \n"
     ]
    }
   ],
   "source": [
    "als_model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.01,\n",
    "    iterations=20,\n",
    "    calculate_training_loss=True\n",
    ")\n",
    "als_model.fit(item_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42977, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.user_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262437, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.item_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_factors = als_model.item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.05262380e-03, -4.06796020e-03, -4.03186120e-03, ...,\n",
       "         1.55082997e-02,  3.85848503e-03,  5.13289729e-03],\n",
       "       [ 1.13298872e-03, -1.84161053e-03,  7.36503804e-04, ...,\n",
       "         7.61957839e-04, -1.35281123e-03, -5.82765148e-04],\n",
       "       [ 8.29866854e-04, -2.04821746e-03,  1.00235466e-03, ...,\n",
       "         1.20832480e-03,  1.77613998e-04, -5.55109698e-04],\n",
       "       ...,\n",
       "       [ 3.12762240e-13,  7.91967240e-13,  6.88148052e-13, ...,\n",
       "         3.03570672e-13,  5.03090679e-13,  5.57207275e-13],\n",
       "       [-3.79268755e-03,  1.41567586e-03, -2.53510545e-03, ...,\n",
       "         1.70553988e-03, -2.13955436e-03, -1.99202754e-04],\n",
       "       [-1.11668836e-04, -1.10197783e-04, -5.40284556e-04, ...,\n",
       "         6.78873621e-04,  2.43592658e-03,  1.34661025e-03]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.0526238e-03, -4.0679602e-03, -4.0318612e-03, -4.4577086e-04,\n",
       "       -1.0077970e-03,  3.5765825e-03, -3.7928505e-03, -2.0355291e-03,\n",
       "        5.7448326e-03,  6.0828752e-03,  7.0429774e-04,  3.8939731e-03,\n",
       "       -3.0015018e-03, -1.0716072e-03,  8.4128249e-03, -1.0839609e-03,\n",
       "        3.4444178e-03, -7.2769960e-03,  2.8345420e-04,  1.1460707e-03,\n",
       "        3.9740289e-03, -1.2699587e-03,  7.7811764e-03,  5.7185376e-03,\n",
       "        2.0686530e-03, -6.3279546e-03,  1.0030845e-02,  1.8581138e-03,\n",
       "       -5.0841016e-03,  6.0986234e-03,  1.0523131e-02,  6.7430054e-04,\n",
       "        1.5817288e-03, -1.9593611e-03, -5.7953843e-03, -9.1385422e-03,\n",
       "        4.8826533e-04, -4.0258975e-03,  3.7696105e-03, -7.3920283e-03,\n",
       "        1.6722352e-03, -7.1544624e-03,  3.5342048e-03,  4.8683264e-04,\n",
       "       -2.9618014e-04,  8.4422491e-03,  3.1182331e-03, -1.2281337e-03,\n",
       "       -4.5516933e-03,  4.0876297e-03,  5.8943468e-05,  2.4722945e-03,\n",
       "       -2.3465338e-03,  1.6390193e-04,  5.4877187e-04,  3.7642368e-03,\n",
       "        4.8668124e-03, -8.3817206e-03,  5.0683797e-04,  1.3124490e-02,\n",
       "        2.8957101e-03,  1.5508300e-02,  3.8584850e-03,  5.1328973e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.item_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064279005"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.item_factors[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## items_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_DIR = f'{DATA_DIR}preproc/'\n",
    "items_matrix = np.load(f'{PREPROC_DIR}items_matrix2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328050, 160)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_matrix_train, items_matrix_test = items_matrix[:split_n], items_matrix[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262440, 160), (65610, 160))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix_train.shape, items_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert(als_item_factors.shape[0] == items_matrix_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model to predict als-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_EMBEDDING_SHAPE = 160\n",
    "ALS_EMBEDDING_SHAPE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = reset_tf_session()\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    item_embedding = tf.placeholder('float32', shape=[None, ITEM_EMBEDDING_SHAPE])\n",
    "    als_item = tf.placeholder('float32', shape=[None, ALS_EMBEDDING_SHAPE])\n",
    "    \n",
    "    layer = tf.layers.dense(item_embedding, 256, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 256, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 128, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 64, None, kernel_initializer=tf.random_normal_initializer)\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.square(layer - als_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer operation to minimize the loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_step = optimizer.minimize(model.loss)\n",
    "\n",
    "# will be used to save/load network weights.\n",
    "# you need to reset your default graph and define it in the same way to be able to load the saved weights!\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# intialize all variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "N_BATCHES_PER_EPOCH = 90_000\n",
    "\n",
    "# SPLIT_N = 262437\n",
    "SPLIT_N = min(als_item_factors.shape[0], items_matrix_train.shape[0])\n",
    "als_item_factors = als_item_factors[:SPLIT_N]\n",
    "items_matrix_train = items_matrix_train[:SPLIT_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_embedding_als_batch():\n",
    "    indxs = np.random.randint(0, SPLIT_N, BATCH_SIZE)\n",
    "    return {\n",
    "        model.item_embedding: items_matrix_train[indxs],\n",
    "        model.als_item: als_item_factors[indxs]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c743869bec3457a92c0c88deb490f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 25839046.61228021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5f6d922d4740e98b9e6843d846e627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 7.492560412728124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c194c7bae1144e78e7c45a5d8de0d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 7.36990354383207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bba6bf794843b4bae94dceb05d09ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 7.5161634179261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e8194dab2a4b5e84903ecc7775ab5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 7.517902467620207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4634003ed1144518a4bc45bddeca73ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 7.4348320710059665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22dc5f400984189aea0c53a42e3ecb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 7.573778399551577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5f31014a804aa8ba2a8a685fe5e0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 7.406600799159871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38c810547e64b52be03b6b473511c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 7.50356530638155\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# to make training reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss = 0\n",
    "    pbar = tqdm_utils.tqdm_notebook_failsafe(range(N_BATCHES_PER_EPOCH))\n",
    "    counter = 0\n",
    "    for i, _ in enumerate(pbar):\n",
    "        batch_train_loss, _ = sess.run(\n",
    "            [model.loss, train_step], \n",
    "            items_embedding_als_batch()\n",
    "        )\n",
    "        train_loss += batch_train_loss\n",
    "        counter += 1\n",
    "        pbar.set_description(\"Training loss: %f\" % (train_loss / counter))\n",
    "        \n",
    "    train_loss /= N_BATCHES_PER_EPOCH\n",
    "    \n",
    "    print('Epoch: {}, train loss: {}'.format(epoch, train_loss))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65610, 160)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.5 ms, sys: 29.3 ms, total: 79.8 ms\n",
      "Wall time: 78.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "als_item_factors_predict = sess.run(model.layer, feed_dict={model.item_embedding: items_matrix_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65610, 64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_item_factors_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262440"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017362930558815215"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(als_item_factors[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351],\n",
       "       [ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351],\n",
       "       [ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351],\n",
       "       ...,\n",
       "       [ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351],\n",
       "       [ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351],\n",
       "       [ 0.00864422,  0.0083251 ,  0.01091623, ..., -0.01176611,\n",
       "         0.00303996,  0.00153351]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_item_factors_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069c0a358f6e4024ae1f845c65b9277f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "eps = 1e-06\n",
    "for _, (idd, items, ratings) in tqdm(test_df.iterrows()):\n",
    "    predictied_ratings = als_item_factors_predict.dot(als_model.user_factors[idd])[items-split_n]+mean_ratings[idd]\n",
    "#     predictied_ratings = (predictied_ratings - predictied_ratings.min()) / (predictied_ratings.max() - predictied_ratings.min())\n",
    "    predictied_ratings = np.clip(predictied_ratings, eps, 1 - eps)\n",
    "#     print(predictied_ratings[ratings==1])\n",
    "    if (ratings == 0).all() or (ratings == 1).all():\n",
    "        continue\n",
    "    loss += log_loss(ratings.astype(np.float64), predictied_ratings)\n",
    "loss /= test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3671378158508988"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412, 0.03495412, 0.03495412, 0.03495412, 0.03495412,\n",
       "       0.03495412], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictied_ratings[ratings==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
