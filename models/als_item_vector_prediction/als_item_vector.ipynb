{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import gzip\n",
    "import json\n",
    "import implicit\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL = False\n",
    "HOME_DIR = '/mnt/E/Projects/Content-based-Neural-Recommender-Systems/' if IS_LOCAL else '../../'\n",
    "os.environ['HOME_DIR'] = HOME_DIR\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from utils.prepare_data import utf8_preview\n",
    "\n",
    "DATA_DIR = f'{HOME_DIR}data/zen/'\n",
    "WORKING_DIR = f'{HOME_DIR}/models/als_item_vector_prediction/'\n",
    "os.chdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eb083267304f2696524c6301d16cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='loading items', max=1, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_size = 96\n",
    "items_df = []\n",
    "for line in tqdm(gzip.GzipFile(f\"{DATA_DIR}items.json.gz\", \"r\"), 'loading items'):\n",
    "    j = json.loads(line)\n",
    "    j[\"content\"] = j[\"content\"].encode(\"utf8\")  # storing in utf8 saves RAM\n",
    "    j[\"title\"] = j[\"title\"].encode(\"utf8\")\n",
    "    if np.isnan(j[\"image\"]).any():\n",
    "        j[\"image\"] = [0]*image_size\n",
    "    items_df.append(j)\n",
    "items_df = pd.DataFrame(items_df).apply(utf8_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_n = int(items_df.shape[0]*(1-test_size))\n",
    "items_train_df, items_test_df = items_df.iloc[:split_n], items_df.iloc[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262440, 4), (65610, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_train_df.shape, items_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_items(user_items, user_ratings, split_n):\n",
    "    user_items, user_ratings = np.array(user_items), np.array(user_ratings)\n",
    "    train_idxs = user_items < split_n\n",
    "    test_idxs = train_idxs ^ True\n",
    "    return (user_items[train_idxs], user_ratings[train_idxs]), (user_items[test_idxs], user_ratings[test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e665a5949041491299ab1ea78c66c1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='loading users', max=1, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "users_train_df, users_test_df = [], []\n",
    "for line in tqdm(gzip.GzipFile(f\"{DATA_DIR}train.json.gz\", \"r\"), 'loading users'):\n",
    "    j = json.loads(line)\n",
    "    user_items = []\n",
    "    user_ratings = []\n",
    "    for item, rating in j[\"trainRatings\"].items():\n",
    "        user_items.append(int(item))\n",
    "        user_ratings.append(int(rating))\n",
    "\n",
    "    user_train, user_test = split_items(user_items, user_ratings, split_n)\n",
    "    users_train_df.append({\n",
    "        'userId': j[\"userId\"],\n",
    "        'userItems': np.array(user_train[0]),\n",
    "        'userRatings': np.array(user_train[1]),\n",
    "    })\n",
    "    users_test_df.append({\n",
    "        'userId': j[\"userId\"],\n",
    "        'userItems': np.array(user_test[0]),\n",
    "        'userRatings': np.array(user_test[1]),\n",
    "    })\n",
    "users_train_df = pd.DataFrame(users_train_df)\n",
    "users_test_df = pd.DataFrame(users_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = users_train_df, users_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for t in train_df['userItems']:\n",
    "    tmp += t.tolist()\n",
    "for t in test_df['userItems']:\n",
    "    tmp += t.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328049"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262436"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_df['userItems'].apply(max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSR-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.concatenate([[v]*v_len for v, v_len in zip(\n",
    "    train_df['userId'].values, train_df['userItems'].apply(len).values)])\n",
    "items_ids = np.concatenate(train_df['userItems'].values)\n",
    "ratings = np.concatenate(np.array(list(map(lambda x: x - x.mean(), train_df['userRatings'].values))))\n",
    "item_user_data = sparse.csr_matrix((ratings, (items_ids, user_ids)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = np.array(list(map(np.mean, train_df['userRatings'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262437, 42977)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_n: 42977\titems_n: 262436\n"
     ]
    }
   ],
   "source": [
    "users_n = train_df.shape[0]\n",
    "items_n = train_df['userItems'].apply(max).max()\n",
    "print(f'users_n: {users_n}\\titems_n: {items_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 20.0/20 [02:20<00:00,  7.00s/it, loss=-.0051] \n"
     ]
    }
   ],
   "source": [
    "als_model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.01,\n",
    "    iterations=20,\n",
    "    calculate_training_loss=True\n",
    ")\n",
    "als_model.fit(item_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42977, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.user_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262437, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.item_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_factors = als_model.item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## items_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_DIR = f'{DATA_DIR}preproc/'\n",
    "items_matrix = np.load(f'{PREPROC_DIR}items_matrix2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328050, 160)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_matrix_train, items_matrix_test = items_matrix[:split_n], items_matrix[split_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262440, 160), (65610, 160))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix_train.shape, items_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert(als_item_factors.shape[0] == items_matrix_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model to predict als-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_EMBEDDING_SHAPE = 160\n",
    "ALS_EMBEDDING_SHAPE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = reset_tf_session()\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    item_embedding = tf.placeholder('float32', shape=[None, ITEM_EMBEDDING_SHAPE])\n",
    "    als_item = tf.placeholder('float32', shape=[None, ALS_EMBEDDING_SHAPE])\n",
    "    \n",
    "    layer = tf.layers.dense(item_embedding, 256, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 256, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 128, tf.nn.elu, kernel_initializer=tf.random_normal_initializer)\n",
    "    layer = tf.layers.dropout(layer, 0.2)\n",
    "    layer = tf.layers.dense(layer, 64, None, kernel_initializer=tf.random_normal_initializer)\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.square(layer - als_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer operation to minimize the loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_step = optimizer.minimize(model.loss)\n",
    "\n",
    "# will be used to save/load network weights.\n",
    "# you need to reset your default graph and define it in the same way to be able to load the saved weights!\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# intialize all variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "N_BATCHES_PER_EPOCH = 90_000\n",
    "\n",
    "# SPLIT_N = 262437\n",
    "SPLIT_N = min(als_item_factors.shape[0], items_matrix_train.shape[0])\n",
    "als_item_factors = als_item_factors[:SPLIT_N]\n",
    "items_matrix_train = items_matrix_train[:SPLIT_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_embedding_als_batch():\n",
    "    indxs = np.random.randint(0, SPLIT_N, BATCH_SIZE)\n",
    "    return {\n",
    "        model.item_embedding: items_matrix_train[indxs],\n",
    "        model.als_item: als_item_factors[indxs]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c743869bec3457a92c0c88deb490f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=90000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to make training reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss = 0\n",
    "    pbar = tqdm_utils.tqdm_notebook_failsafe(range(N_BATCHES_PER_EPOCH))\n",
    "    counter = 0\n",
    "    for i, _ in enumerate(pbar):\n",
    "        batch_train_loss, _ = sess.run(\n",
    "            [model.loss, train_step], \n",
    "            items_embedding_als_batch()\n",
    "        )\n",
    "        train_loss += batch_train_loss\n",
    "        counter += 1\n",
    "        pbar.set_description(\"Training loss: %f\" % (train_loss / counter))\n",
    "        \n",
    "    train_loss /= N_BATCHES_PER_EPOCH\n",
    "    \n",
    "    print('Epoch: {}, train loss: {}'.format(epoch, train_loss))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "als_item_factors_predict = sess.run(model.layer, feed_dict={model.item_embedding: items_matrix_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_factors_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(als_item_factors[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_factors_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "eps = 1e-06\n",
    "for _, (idd, items, ratings) in tqdm(test_df.iterrows()):\n",
    "    predictied_ratings = als_item_factors_predict.dot(als_model.user_factors[idd])[items-split_n]+mean_ratings[idd]\n",
    "#     predictied_ratings = (predictied_ratings - predictied_ratings.min()) / (predictied_ratings.max() - predictied_ratings.min())\n",
    "    predictied_ratings = np.clip(predictied_ratings, eps, 1 - eps)\n",
    "#     print(predictied_ratings[ratings==1])\n",
    "    if (ratings == 0).all() or (ratings == 1).all():\n",
    "        continue\n",
    "    loss += log_loss(ratings.astype(np.float64), predictied_ratings)\n",
    "loss /= test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictied_ratings[ratings==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
